{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heeeeee0129/2022S-ML/blob/main/HW4_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HW4 :: DNN**\n",
        "## 과제 목표\n",
        "* 간단한 Three Layer Network를 구현하기\n",
        "* Pytorch를 사용하여 DNN 구현 후 학습과 테스트하기\n",
        "  \n",
        "  \n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "EXvAS7OZkg_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐  이번 과제는 bb에 코랩 링크, ipynb 파일만 업로드합니다(HW3와 동일하게).   \n",
        "⭐  작성한 코드에 **간단한 주석을 반드시 달아주세요**!  \n",
        "⭐  코딩할 부분을 제외하고는 수정하지 마세요. 수정 시 감점입니다."
      ],
      "metadata": {
        "id": "k5IhqPYwmnUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **문제 1 - Three Layer Network**\n",
        "```class Sigmoid```와 ```Affine```을 구현한 후 이 두 class를 사용하여 ```class ThreeLayerNet```를 완성하세요. \n",
        "* 코드 참고 : deep learning from scratch"
      ],
      "metadata": {
        "id": "OKfJ8-LiFOr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-1\n",
        "class sigmoid의 forward 함수를 구현하세요.  \n",
        "힌트) sigmoid 함수 식"
      ],
      "metadata": {
        "id": "FrrWMAJx6FUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QSI6QIBkCPWP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.params = []\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      #############################################\n",
        "      ################### 문제 1-1 #################\n",
        "      ############# sigmoid forward 구현 ###########\n",
        "      #############################################\n",
        "        # 한 줄로 구현\n",
        "        result = (1/(1+np.exp(-x))) ## 시그모이드 함수 식: S(x) = 1/(1+e^(-x))\n",
        "      #############################################\n",
        "      \n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-2\n",
        "class Affine의 forward 함수를 구현하세요.  \n",
        "힌트) affine 함수 식"
      ],
      "metadata": {
        "id": "1YcAkmtN6UXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine: # Affine은 Fully Connect를 의미합니다\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "      #############################################\n",
        "      ################### 문제 1-2 #################\n",
        "      ############# affine forward 구현 ############\n",
        "      #############################################\n",
        "        # 코드 작성\n",
        "        W, b = self.params\n",
        "        out = np.matmul(x,W)+b   ## 아핀 변환: Y = WX + b\n",
        "      #############################################\n",
        "      \n",
        "        return out\n"
      ],
      "metadata": {
        "id": "Ds05drVvG5O_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-3\n",
        "\n",
        "  각 layer의 parameter를 ```np.random.randn()``` 를 사용하여 초기화하세요.  \n",
        "  * 조건) ```class ThreeLayerNet```은 총 3개의 fully connected layer로 구성됩니다.\n",
        "  * 힌트) 차원을 잘 고려하세요. \n"
      ],
      "metadata": {
        "id": "aX3vaESK6jp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-4\n",
        "  문제1-1, 2에서 구현한 class를 사용하여 ThreeLayerNet의 layer를 구성하세요.\n",
        "  * 조건) ```class ThreeLayerNet```은 총 3개의 fully connected layer로 구성됩니다.\n",
        "  * 힌트) 차원을 잘 고려하세요."
      ],
      "metadata": {
        "id": "qoPlnkHg_18J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ThreeLayerNet:\n",
        "    def __init__(self, input_size, first_hidden_size, second_hidden_size, output_size):\n",
        "        I, H_1, H_2,O = input_size, first_hidden_size, second_hidden_size, output_size\n",
        "\n",
        "      #############################################\n",
        "      ################### 문제 1-3 #################\n",
        "      ######### parameter initialization ##########\n",
        "      #############################################\n",
        "        # 코드 작성\n",
        "        ## 파라미터 초기화\n",
        "        Wh_1 = np.random.randn(I, H_1)        ## 크기가 (I, H_1) 인 랜덤 숫자로 초기화\n",
        "        bh_1 = np.random.randn(H_1)           ## 크기가 (H_1) 인 랜덤 숫자로 초기화\n",
        "        Wh_2 = np.random.randn(H_1, H_2)      ## 크기가 (H_1, H_2) 인 랜덤 숫자로 초기화\n",
        "        bh_2 = np.random.randn(H_2)           ## 크기가 (H_2) 인 랜덤 숫자로 초기화\n",
        "        Wy = np.random.randn(H_2, O)          ## 크기가 (H_2, O) 인 랜덤 숫자로 초기화\n",
        "        by = np.random.randn(O)               ## 크기가 (O) 인 랜덤 숫자로 초기화\n",
        "\n",
        "      #########################################\n",
        "        \n",
        "\n",
        "        self.layers = [\n",
        "        #############################################\n",
        "        ################### 문제 1-4 #################\n",
        "        ############### stack layers ################\n",
        "        #############################################          \n",
        "            # 코드 작성\n",
        "            Affine(Wh_1, bh_1),\n",
        "            Sigmoid(),\n",
        "            Affine(Wh_2, bh_2),\n",
        "            Sigmoid(),\n",
        "            Affine(Wy, by)           ## 레이어 쌓기-! \n",
        "\n",
        "        #############################################    \n",
        "        ]\n",
        "\n",
        "        # 모든 weight 를 담은 리스트 생성\n",
        "        self.params = []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "VmHw4K5DG3uv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy data로 모델 실행해보기\n",
        "x = np.random.randn(784, 100)\n",
        "model = ThreeLayerNet(100, 50, 30, 10)\n",
        "s = model.predict(x)\n",
        "print(s)"
      ],
      "metadata": {
        "id": "SNI0xGraFAAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8218a85d-fe61-470e-f885-b2ee9f4ec2f3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5.70417067  9.26458337  0.27811591 ...  0.307068    9.01537244\n",
            "  -4.2767198 ]\n",
            " [ 2.04409276  3.77640463 -2.80158859 ...  2.29165827  6.14371699\n",
            "  -0.48198112]\n",
            " [ 2.3251568   5.72820729 -2.85673085 ...  3.4731695   6.84707018\n",
            "  -2.32705347]\n",
            " ...\n",
            " [ 2.78092886  3.63683114 -2.57442679 ...  7.70120665  7.12993321\n",
            "   1.25650076]\n",
            " [ 4.79991698  4.01636002 -0.13673985 ...  3.85023885  7.18491696\n",
            "  -0.11706385]\n",
            " [ 5.35879345  5.04285153 -1.11042905 ... -1.48551811  6.70613682\n",
            "  -4.51174366]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FtZZAx7vovt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 2 - Implementing DNN using Pytorch\n",
        "문제 1에서는 Pytorch를 사용하지 않고 DNN을 구현해보았습니다.  \n",
        "문제 2에서는 Pytorch를 사용하여 DNN을 구현하고 MNIST 데이터로 분류 모델 학습을 진행합니다.\n",
        "* 코드 참고: pytorch 공식 튜토리얼"
      ],
      "metadata": {
        "id": "hOzYC0u5GfkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 importing\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "LKcI43VULpeQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Data**"
      ],
      "metadata": {
        "id": "WCbWy3jAMGuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True, # training data\n",
        "    download=True,\n",
        "    transform=ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# Load test data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # test data\n",
        "    download=True,\n",
        "    transform=ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# data loader\n",
        "# train, test 각각의 data loader 생성\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=1, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "D9DqIegtLnz9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check loaded data**\n",
        "train_loader를 사용하여 하나의 데이터를 로드한 후 이 데이터가 어떤 숫자의 데이터인지 이미지로 확인해봅니다."
      ],
      "metadata": {
        "id": "QtJVlNT9A_KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train feature와 label을 train_loader로부터 가져오기\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ],
      "metadata": {
        "id": "IF90dcyJPhVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16abae4-0483-4c01-c6ef-9d431668a53f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([1, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지로 확인\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "00Wypwb2Pr-r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "cf5e7f19-0d2a-4423-bce7-470e04dea94a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-1\n",
        "4개의 linear layer와 3개의 ReLU layer를 가진 네트워크를 구성하세요.\n",
        "\n"
      ],
      "metadata": {
        "id": "BB_Qe54pB8_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-2\n",
        "forward 함수의 빈칸을 구현하세요."
      ],
      "metadata": {
        "id": "mK5ukeeECYJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten() # 28x28 이미지를 784 픽셀 값의 배열로 변경\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            \n",
        "            nn.Linear(in_features=28*28, out_features=512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #############################################\n",
        "            ################### 문제 2-1 #################\n",
        "            # 4개의 linear layer와 3개의 ReLU layer를 구성하세요\n",
        "            # (위 Linear 포함 4개, ReLU layer 포함 3개를 의미)\n",
        "            #############################################\n",
        "            \n",
        "            # 시작 차원, 끝 차원 잘 고려하여 작성하기\n",
        "            # 중간 차원은 임의로 설정 가능\n",
        "            nn.Linear(in_features = 512, out_features = 256), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features = 256, out_features = 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features = 64, out_features = 10), ## linear 레이어 : 끝차원 10 , linear layer 총 4개, relu layer 총 3개\n",
        "            ## 최종적으로 10개의 확률적 출력\n",
        "\n",
        "            #############################################\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #############################################\n",
        "        ################### 문제 2-2 #################\n",
        "        # forward 함수 구현\n",
        "        #############################################\n",
        "        # 코드 작성\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)  ## linear_relu_stack: sequential 모듈의 컨테이너. 데이터는 모듈들을 통해 전달됨. \n",
        "        #############################################\n",
        "        return logits # forward 결과 저장"
      ],
      "metadata": {
        "id": "zme9j_4hMiA2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cpu OR gpu 설정\n",
        "# gpu가 있을 경우, device로 cuda를 사용함\n",
        "# colab에서 '런타임 유형 변경'을 하면 gpu 사용할 수 있음\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "kfBLbfwUJgtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cee5f5-5eb8-4189-acda-3c138ebd03e1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device) # device로 Network 전송\n",
        "print(model) # 모델 구조 확인"
      ],
      "metadata": {
        "id": "ifGukRqQOUyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd824eb-28fa-4534-959a-fa8f18b0227f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=64, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 앞에서 출력해보았던 train_features[0](1개의 데이터)에 대해서 모델 학습 결과 확인해보기\n",
        "logits = model(train_features[0]) # 일부 백그라운드 연산들과 함께 모델의 forward 를 실행 \n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "id": "MdOf0Rd1VEi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f433dd6-1bff-49d0-d513-216e589f0615"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the Network** \n",
        "epoch과 batch를 활용하여 모델을 학습시켜 봅시다."
      ],
      "metadata": {
        "id": "J5G6rO77V7OR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-3\n",
        "모델의 forward, backward, optimize 하는 부분을 주어진 칸에 구현하세요."
      ],
      "metadata": {
        "id": "n7RwQwKDCjOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)"
      ],
      "metadata": {
        "id": "y7jdCHQphsIO"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter 설정\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # optimizer\n",
        "\n",
        "n_epoch = 3 # the number of epochs\n",
        "n_batch = 32 # the number of batches"
      ],
      "metadata": {
        "id": "XGXKm0pHhnoO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loader 설정하기\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=n_batch, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=n_batch, shuffle=True)"
      ],
      "metadata": {
        "id": "s3viP29EipLg"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # input data 가져오기\n",
        "        # data 는 [inputs, labels]로 구성된 리스트\n",
        "        inputs, labels = data\n",
        "\n",
        "        # optimizer의 파라미터 gradient를 0으로 설정\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #############################################\n",
        "        ################### 문제 2-3 #################\n",
        "        # forward, backward, optimize \n",
        "        #############################################\n",
        "          # 코드 작성\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()   ## loss의 Gradient 계산\n",
        "        optimizer.step() ## 최적화\n",
        "\n",
        "        #############################################\n",
        "\n",
        "        # loss 출력\n",
        "        running_loss += loss.item()\n",
        "        if i % n_batch == 0:    # print every n_batch mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / n_batch:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "m6ByMb4whKFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dbc348e-fd74-4a51-834f-103299efaa2c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.072\n",
            "[1,    33] loss: 2.309\n",
            "[1,    65] loss: 2.302\n",
            "[1,    97] loss: 2.299\n",
            "[1,   129] loss: 2.294\n",
            "[1,   161] loss: 2.291\n",
            "[1,   193] loss: 2.291\n",
            "[1,   225] loss: 2.285\n",
            "[1,   257] loss: 2.283\n",
            "[1,   289] loss: 2.277\n",
            "[1,   321] loss: 2.270\n",
            "[1,   353] loss: 2.266\n",
            "[1,   385] loss: 2.259\n",
            "[1,   417] loss: 2.251\n",
            "[1,   449] loss: 2.242\n",
            "[1,   481] loss: 2.233\n",
            "[1,   513] loss: 2.221\n",
            "[1,   545] loss: 2.213\n",
            "[1,   577] loss: 2.192\n",
            "[1,   609] loss: 2.173\n",
            "[1,   641] loss: 2.144\n",
            "[1,   673] loss: 2.132\n",
            "[1,   705] loss: 2.090\n",
            "[1,   737] loss: 2.060\n",
            "[1,   769] loss: 2.021\n",
            "[1,   801] loss: 1.958\n",
            "[1,   833] loss: 1.904\n",
            "[1,   865] loss: 1.819\n",
            "[1,   897] loss: 1.736\n",
            "[1,   929] loss: 1.649\n",
            "[1,   961] loss: 1.557\n",
            "[1,   993] loss: 1.437\n",
            "[1,  1025] loss: 1.358\n",
            "[1,  1057] loss: 1.263\n",
            "[1,  1089] loss: 1.178\n",
            "[1,  1121] loss: 1.095\n",
            "[1,  1153] loss: 1.073\n",
            "[1,  1185] loss: 0.992\n",
            "[1,  1217] loss: 0.964\n",
            "[1,  1249] loss: 0.938\n",
            "[1,  1281] loss: 0.901\n",
            "[1,  1313] loss: 0.815\n",
            "[1,  1345] loss: 0.812\n",
            "[1,  1377] loss: 0.797\n",
            "[1,  1409] loss: 0.748\n",
            "[1,  1441] loss: 0.703\n",
            "[1,  1473] loss: 0.742\n",
            "[1,  1505] loss: 0.711\n",
            "[1,  1537] loss: 0.722\n",
            "[1,  1569] loss: 0.628\n",
            "[1,  1601] loss: 0.652\n",
            "[1,  1633] loss: 0.637\n",
            "[1,  1665] loss: 0.587\n",
            "[1,  1697] loss: 0.622\n",
            "[1,  1729] loss: 0.599\n",
            "[1,  1761] loss: 0.617\n",
            "[1,  1793] loss: 0.584\n",
            "[1,  1825] loss: 0.535\n",
            "[1,  1857] loss: 0.540\n",
            "[2,     1] loss: 0.024\n",
            "[2,    33] loss: 0.563\n",
            "[2,    65] loss: 0.529\n",
            "[2,    97] loss: 0.576\n",
            "[2,   129] loss: 0.516\n",
            "[2,   161] loss: 0.545\n",
            "[2,   193] loss: 0.525\n",
            "[2,   225] loss: 0.543\n",
            "[2,   257] loss: 0.533\n",
            "[2,   289] loss: 0.474\n",
            "[2,   321] loss: 0.495\n",
            "[2,   353] loss: 0.564\n",
            "[2,   385] loss: 0.530\n",
            "[2,   417] loss: 0.458\n",
            "[2,   449] loss: 0.479\n",
            "[2,   481] loss: 0.454\n",
            "[2,   513] loss: 0.491\n",
            "[2,   545] loss: 0.502\n",
            "[2,   577] loss: 0.514\n",
            "[2,   609] loss: 0.427\n",
            "[2,   641] loss: 0.415\n",
            "[2,   673] loss: 0.477\n",
            "[2,   705] loss: 0.454\n",
            "[2,   737] loss: 0.403\n",
            "[2,   769] loss: 0.436\n",
            "[2,   801] loss: 0.401\n",
            "[2,   833] loss: 0.432\n",
            "[2,   865] loss: 0.435\n",
            "[2,   897] loss: 0.398\n",
            "[2,   929] loss: 0.446\n",
            "[2,   961] loss: 0.445\n",
            "[2,   993] loss: 0.429\n",
            "[2,  1025] loss: 0.404\n",
            "[2,  1057] loss: 0.387\n",
            "[2,  1089] loss: 0.478\n",
            "[2,  1121] loss: 0.401\n",
            "[2,  1153] loss: 0.422\n",
            "[2,  1185] loss: 0.392\n",
            "[2,  1217] loss: 0.410\n",
            "[2,  1249] loss: 0.401\n",
            "[2,  1281] loss: 0.395\n",
            "[2,  1313] loss: 0.372\n",
            "[2,  1345] loss: 0.379\n",
            "[2,  1377] loss: 0.404\n",
            "[2,  1409] loss: 0.393\n",
            "[2,  1441] loss: 0.433\n",
            "[2,  1473] loss: 0.361\n",
            "[2,  1505] loss: 0.366\n",
            "[2,  1537] loss: 0.333\n",
            "[2,  1569] loss: 0.339\n",
            "[2,  1601] loss: 0.364\n",
            "[2,  1633] loss: 0.393\n",
            "[2,  1665] loss: 0.396\n",
            "[2,  1697] loss: 0.414\n",
            "[2,  1729] loss: 0.376\n",
            "[2,  1761] loss: 0.356\n",
            "[2,  1793] loss: 0.337\n",
            "[2,  1825] loss: 0.365\n",
            "[2,  1857] loss: 0.355\n",
            "[3,     1] loss: 0.005\n",
            "[3,    33] loss: 0.337\n",
            "[3,    65] loss: 0.335\n",
            "[3,    97] loss: 0.340\n",
            "[3,   129] loss: 0.347\n",
            "[3,   161] loss: 0.331\n",
            "[3,   193] loss: 0.370\n",
            "[3,   225] loss: 0.351\n",
            "[3,   257] loss: 0.374\n",
            "[3,   289] loss: 0.340\n",
            "[3,   321] loss: 0.327\n",
            "[3,   353] loss: 0.336\n",
            "[3,   385] loss: 0.344\n",
            "[3,   417] loss: 0.359\n",
            "[3,   449] loss: 0.328\n",
            "[3,   481] loss: 0.341\n",
            "[3,   513] loss: 0.287\n",
            "[3,   545] loss: 0.314\n",
            "[3,   577] loss: 0.348\n",
            "[3,   609] loss: 0.350\n",
            "[3,   641] loss: 0.329\n",
            "[3,   673] loss: 0.375\n",
            "[3,   705] loss: 0.387\n",
            "[3,   737] loss: 0.354\n",
            "[3,   769] loss: 0.351\n",
            "[3,   801] loss: 0.344\n",
            "[3,   833] loss: 0.344\n",
            "[3,   865] loss: 0.353\n",
            "[3,   897] loss: 0.304\n",
            "[3,   929] loss: 0.322\n",
            "[3,   961] loss: 0.287\n",
            "[3,   993] loss: 0.302\n",
            "[3,  1025] loss: 0.368\n",
            "[3,  1057] loss: 0.266\n",
            "[3,  1089] loss: 0.363\n",
            "[3,  1121] loss: 0.276\n",
            "[3,  1153] loss: 0.296\n",
            "[3,  1185] loss: 0.316\n",
            "[3,  1217] loss: 0.296\n",
            "[3,  1249] loss: 0.317\n",
            "[3,  1281] loss: 0.289\n",
            "[3,  1313] loss: 0.318\n",
            "[3,  1345] loss: 0.267\n",
            "[3,  1377] loss: 0.293\n",
            "[3,  1409] loss: 0.359\n",
            "[3,  1441] loss: 0.309\n",
            "[3,  1473] loss: 0.266\n",
            "[3,  1505] loss: 0.313\n",
            "[3,  1537] loss: 0.361\n",
            "[3,  1569] loss: 0.292\n",
            "[3,  1601] loss: 0.296\n",
            "[3,  1633] loss: 0.348\n",
            "[3,  1665] loss: 0.266\n",
            "[3,  1697] loss: 0.287\n",
            "[3,  1729] loss: 0.308\n",
            "[3,  1761] loss: 0.260\n",
            "[3,  1793] loss: 0.311\n",
            "[3,  1825] loss: 0.280\n",
            "[3,  1857] loss: 0.272\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test the Network**"
      ],
      "metadata": {
        "id": "XnqNJjGki4JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test feature와 label을 test_loader로부터 가져오기\n",
        "test_features, test_labels = next(iter(test_loader))\n",
        "print(f\"Feature batch shape: {test_features.size()}\")\n",
        "print(f\"Labels batch shape: {test_labels.size()}\")"
      ],
      "metadata": {
        "id": "CO1AMDEAjGrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9438df57-3be8-4b6e-dcf6-840d3cfbb830"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([32, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1개 이미지 확인해보기\n",
        "\n",
        "logits = model(test_features[0]) # 일부 백그라운드 연산들과 함께 모델의 forward 를 실행 \n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "\n",
        "\n",
        "img = test_features[0].squeeze()\n",
        "label = test_labels[0]\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Predicted class: {y_pred}\")\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "bgC3vITkjWdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "52edf496-d591-4ffd-e7c5-e7b73db42e77"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([8])\n",
            "Label: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 test data에 대한 결과 확인\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # 모델을 학습하는 것이 아니므로 gradient 계산을 할 필요가 없음\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "RE_tglcsmmRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f0e9fd-2509-4e8c-fabf-bcd7ac8734bd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 92 %\n"
          ]
        }
      ]
    }
  ]
}